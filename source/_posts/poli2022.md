---
title: Poli et al. (2022)
subtitle: Contributions of expected learning progress and perceptual novelty to curiosity-driven exploration
date: 2022/08/01
authors:
- Poli, Francesco
- Meyer, Marlene
- Mars, Rogier B
- Hunnius, Sabine
journal: Cognition
paper_url: https://doi.org/10.1016/j.cognition.2022.105119
data_url: osf.io/tqevz/
tags:
- multi-arm bandit
- volatility
- explore/exploit
abstract: 'Exploration is curiosity-driven when it relies on the intrinsic motivation to know rather than on extrinsic rewards. Recent evidence shows that artificial agents perform better on a variety of tasks when their learning is curiosity-driven, and humans often engage in curiosity-driven learning when sampling information from the environment. However, which mechanisms underlie curiosity is still unclear. Here, we let participants freely explore different unknown environments that contained learnable sequences of events with varying degrees of noise and volatility. A hierarchical reinforcement learning model captured how participants were learning in these different kinds of unknown environments, and it also tracked the errors they expected to make and the learning opportunities they were planning to seek. With this computational approach, we show that participants exploratory behavior is guided by learning progress and perceptual novelty. Moreover, we demonstrate an overall tendency of participants to avoid extreme forms of uncertainty. These findings elucidate the cognitive mechanisms that underlie curiosity-driven exploration of unknown environments. Implications of this novel way of quantifying curiosity within a reinforcement learning framework are discussed.'
---

Data from a study in which N=67 participants completed a multi-arm bandit task in which participants freely explored different unknown environments that contained learnable sequences of events with varying degrees of noise and volatility. Participants' exploratory behavior was guided by learning progress and perceptual novelty, and also an overall tendency to avoid extreme forms of uncertainty.
